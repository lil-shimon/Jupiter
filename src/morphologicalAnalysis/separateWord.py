from janome.tokenizer import Tokenizer

t = Tokenizer()

s = "すもももももももものうち"

for token in t.tokenize(s):
    print(token)
    # 出力結果
    # すもも
    # 名詞, 一般, *, *, *, *, すもも, スモモ, スモモ
    # も
    # 助詞, 係助詞, *, *, *, *, も, モ, モ
    # もも
    # 名詞, 一般, *, *, *, *, もも, モモ, モモ
    # も
    # 助詞, 係助詞, *, *, *, *, も, モ, モ
    # もも
    # 名詞, 一般, *, *, *, *, もも, モモ, モモ
    # の
    # 助詞, 連体化, *, *, *, *, の, ノ, ノ
    # うち
    # 名詞, 非自立, 副詞可能, *, *, *, うち, ウチ, ウチ

smoke = "タバコを吸わない人や現在たばこを辞めている人は使用しないで下さい。"

for tok in t.tokenize(smoke):
    print(tok)
    # を
    # 助詞, 格助詞, 一般, *, *, *, を, ヲ, ヲ
    # 吸わ
    # 動詞, 自立, *, *, 五段・ワ行促音便, 未然形, 吸う, スワ, スワ
    # ない
    # 助動詞, *, *, *, 特殊・ナイ, 基本形, ない, ナイ, ナイ
    # 人
    # 名詞, 一般, *, *, *, *, 人, ヒト, ヒト
    # や
    # 助詞, 並立助詞, *, *, *, *, や, ヤ, ヤ
    # 現在
    # 名詞, 副詞可能, *, *, *, *, 現在, ゲンザイ, ゲンザイ
    # たばこ
    # 名詞, 一般, *, *, *, *, たばこ, タバコ, タバコ
    # を
    # 助詞, 格助詞, 一般, *, *, *, を, ヲ, ヲ
    # 辞め
    # 動詞, 自立, *, *, 一段, 連用形, 辞める, ヤメ, ヤメ
    # て
    # 助詞, 接続助詞, *, *, *, *, て, テ, テ
    # いる
    # 動詞, 非自立, *, *, 一段, 基本形, いる, イル, イル
    # 人
    # 名詞, 一般, *, *, *, *, 人, ヒト, ヒト
    # は
    # 助詞, 係助詞, *, *, *, *, は, ハ, ワ
    # 使用
    # 名詞, サ変接続, *, *, *, *, 使用, シヨウ, シヨー
    # し
    # 動詞, 自立, *, *, サ変・スル, 未然形, する, シ, シ
    # ない
    # 助動詞, *, *, *, 特殊・ナイ, 連用デ接続, ない, ナイ, ナイ
    # で
    # 助詞, 接続助詞, *, *, *, *, で, デ, デ
    # 下さい
    # 動詞, 非自立, *, *, 五段・ラ行特殊, 命令ｉ, 下さる, クダサイ, クダサイ
    # 。      記号, 句点, *, *, *, *, 。, 。, 。

sumomo = "すもももももももものうち"

# wakati=Trueで分かち書きをすることができる。結果はリストで出力
word_list = t.tokenize(s, wakati=True)
print(word_list)
# ['すもも', 'も', 'もも', 'も', 'もも', 'の', 'うち']
